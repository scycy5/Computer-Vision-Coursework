{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dbafbaa-4dc4-47cf-a1b0-c7fce000a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk, ImageEnhance\n",
    "import time\n",
    "import imutils\n",
    "\n",
    "class PanoramaBuilder:\n",
    "    \n",
    "    def __init__(self, tk_window):\n",
    "        cv2.ocl.setUseOpenCL(False)\n",
    "        \n",
    "        \"\"\"Initialize instance variables.\"\"\"\n",
    "        self.video_path = None\n",
    "        self.images = []\n",
    "\n",
    "        self.tk_window = tk_window\n",
    "        self.tk_window.title(\"Panorama Builder\")\n",
    "        self.tk_window.geometry(\"900x700\")\n",
    "        self.tk_window.resizable(False, False)\n",
    "        \n",
    "        menu_bar = tk.Menu(self.tk_window)\n",
    "        self.tk_window.config(menu=menu_bar)\n",
    "\n",
    "        menu_bar.add_command(label=\"Generate\", command=self.generate_panorama)\n",
    "\n",
    "        help_menu = tk.Menu(menu_bar, tearoff=False)\n",
    "        help_menu.add_command(label=\"About\", command=self.show_about)\n",
    "        menu_bar.add_cascade(label=\"Help\", menu=help_menu)\n",
    "\n",
    "        menu_bar.add_command(label=\"Exit\", command=self.quit)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.tk_window, width=700, height=500)\n",
    "        self.canvas.pack()        \n",
    "        self.canvas.create_text(350, 250, text=\"Welcome to Panorama Builder\", fill='blue', font=100)        \n",
    "\n",
    "\n",
    "    def update_loading(self, current_image, total_images):\n",
    "        if not hasattr(self, 'fill_line'):\n",
    "            self.fill_line = self.canvas.create_rectangle(1.5, 1.5, 1.5, 23, width=0, fill=\"green\")\n",
    "    \n",
    "        if total_images == 0:\n",
    "            return\n",
    "    \n",
    "        # Calculates the width of the progress bar\n",
    "        new_width = (600 / total_images) * current_image\n",
    "    \n",
    "        # Update the coordinates of the progress bar to reflect the current progress\n",
    "        self.canvas.coords(self.fill_line, 1.5, 1.5, new_width, 23)\n",
    "    \n",
    "        # Prevents current_image from exceeding total_images\n",
    "        ratio = min(1, current_image / total_images)\n",
    "    \n",
    "        # The color gradient transitions from green to red\n",
    "        green_to_red = int(255 * ratio)\n",
    "        red_to_green = 255 - green_to_red\n",
    "        color = f'#{red_to_green:02x}{green_to_red:02x}00'\n",
    "        self.canvas.itemconfig(self.fill_line, fill=color)\n",
    "    \n",
    "        self.tk_window.update()\n",
    "\n",
    "    def enhance(self, image, dfa):\n",
    "        '''Adjust image attributes based on brightness deviation (dfa)'''\n",
    "        brightness = 1.0\n",
    "        contrast = 1.0\n",
    "        sharpness = 1.0\n",
    "    \n",
    "       # Adjust image parameters\n",
    "        if dfa > 0:\n",
    "            brightness -= min(0.1 * abs(dfa) / 128, 0.5)\n",
    "        else:\n",
    "            contrast += min(0.1 * abs(dfa) / 128, 0.5)\n",
    "            sharpness += min(0.1 * abs(dfa) / 128, 0.5)\n",
    "    \n",
    "        try:\n",
    "             # Apply brightness enhancement\n",
    "            enhancer = ImageEnhance.Brightness(Image.fromarray(np.uint8(image)))\n",
    "            image = enhancer.enhance(brightness)\n",
    "    \n",
    "            # Apply contrast enhancement\n",
    "            enhancer = ImageEnhance.Contrast(image)\n",
    "            image = enhancer.enhance(contrast)\n",
    "    \n",
    "            # Apply sharpness enhancement\n",
    "            enhancer = ImageEnhance.Sharpness(image)\n",
    "            image = enhancer.enhance(sharpness)\n",
    "            \n",
    "            return np.array(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error enhancing image: {e}\")\n",
    "            return image\n",
    "\n",
    "\n",
    "    def calculate_coefficient(self, gray_img):\n",
    "        '''Calculate the cofficient'''\n",
    "        # Constants\n",
    "        NUM_HISTOGRAM_BIN = 256\n",
    "    \n",
    "        try:\n",
    "            # Calculate normalized histogram of gray values\n",
    "            hist = cv2.calcHist([gray_img], [0], None, [NUM_HISTOGRAM_BIN], [0, 256]).ravel() / gray_img.size\n",
    "    \n",
    "            # Calculate the mean brightness directly from histogram\n",
    "            mean_brightness = np.dot(hist, np.arange(NUM_HISTOGRAM_BIN))\n",
    "    \n",
    "            # Calculate deviation from the mean brightness (Mean Absolute Deviation, MAD)\n",
    "            deviation_from_mean = np.arange(NUM_HISTOGRAM_BIN) - mean_brightness\n",
    "            mean_absolute_deviation = np.sum(np.abs(deviation_from_mean) * hist)\n",
    "    \n",
    "            # Brightness coefficient, normalized by mean absolute deviation\n",
    "            bc = np.abs(mean_brightness - 128) / mean_absolute_deviation if mean_absolute_deviation != 0 else 0\n",
    "    \n",
    "            # Return the brightness coefficient and the deviation of the mean from 128\n",
    "            dfa = mean_brightness - 128\n",
    "            return bc, dfa\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating image coefficients: {e}\")\n",
    "            return 0, 0  # Default values in case of error\n",
    "\n",
    "\n",
    "    def preprocess_video(self):\n",
    "        if self.video_path:\n",
    "            self.setup_video_processing()\n",
    "            self.process_frames()\n",
    "\n",
    "\n",
    "    def setup_video_processing(self):\n",
    "        \"\"\"Initialize video processing with essential configurations.\"\"\"\n",
    "        self.capture = cv2.VideoCapture(self.video_path)\n",
    "        self.images = []\n",
    "        # ORB for feature detection\n",
    "        self.orb = cv2.ORB_create()\n",
    "        self.total_images = int(self.capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        frame_rate = self.capture.get(cv2.CAP_PROP_FPS)\n",
    "        self.frame_rate = round(frame_rate)\n",
    "        # Dynamically adjust the frame interval threshold based on the frame rate\n",
    "        self.frame_interval = max(1, int(self.frame_rate // 3))\n",
    "        \n",
    "        self.frame_count = 1\n",
    "        self.setup_progress_bar()\n",
    "\n",
    "    def setup_progress_bar(self):\n",
    "        ''' set up progress bar'''\n",
    "        tk.Label(self.tk_window, text='Process Bar').place(x=50, y=80)\n",
    "        self.canvas = tk.Canvas(self.tk_window, width=600, height=22, bg=\"white\")\n",
    "        self.canvas.place(x=150, y=80)\n",
    "        self.update_loading(0, self.total_images)\n",
    "\n",
    "    def process_frames(self):\n",
    "        \"\"\"Process each frame in the video to extract key frames for stitching.\"\"\"\n",
    "        success, last_image = self.capture.read()\n",
    "        if success:\n",
    "            self.process_first_frame(last_image)\n",
    "    \n",
    "        while success:\n",
    "            success, image = self.capture.read()\n",
    "            if success:\n",
    "                # Update the last_image for the next cycle\n",
    "                if self.frame_count % self.frame_interval == 0:\n",
    "                    self.process_subsequent_frame(last_image, image)\n",
    "                last_image = image\n",
    "            self.frame_count += 1\n",
    "    \n",
    "        # Make sure the last frame is processed\n",
    "        self.process_subsequent_frame(last_image, last_image)\n",
    "        self.finalize_progress_bar()\n",
    "\n",
    "\n",
    "    def process_first_frame(self, last_image):\n",
    "        \"\"\"Process the first frame separately to initialize key frame list.\"\"\"\n",
    "        first_image = self.preprocess_image(last_image)\n",
    "        self.images.append(first_image)\n",
    "\n",
    "    def auto_white_balance(self, image):\n",
    "        \"\"\" Apply automatic white balance using the Gray World assumption. \"\"\"\n",
    "        result = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "        \n",
    "        avg_a = np.mean(result[:, :, 1])\n",
    "        avg_b = np.mean(result[:, :, 2])\n",
    "        \n",
    "        result[:, :, 1] = result[:, :, 1] - ((avg_a - 128) * (result[:, :, 1] / 128))\n",
    "        result[:, :, 2] = result[:, :, 2] - ((avg_b - 128) * (result[:, :, 2] / 128))\n",
    "        \n",
    "        return cv2.cvtColor(result, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Preprocess image based on its brightness and feature content.\"\"\"\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        bc, dfa = self.calculate_coefficient(gray_img)\n",
    "        \n",
    "        # Apply automatic white balance\n",
    "        image = self.auto_white_balance(image)\n",
    "        \n",
    "        if bc > 1:\n",
    "            image = self.enhance(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), dfa)\n",
    "        return image\n",
    "    \n",
    "\n",
    "    def process_subsequent_frame(self, last_image, image):\n",
    "        \"\"\"Process and compare the current frame with the last key frame to find matches.\"\"\"\n",
    "        kp1, kp2, valid_matches = self.find_matches(last_image, image)\n",
    "        if len(valid_matches) > 4:\n",
    "            self.handle_valid_matches(kp1, kp2, last_image, image, valid_matches)\n",
    "        else:\n",
    "            self.update_loading(self.frame_count, self.total_images)\n",
    "\n",
    "    def find_matches(self, last_image, image):\n",
    "        '''find match frames'''\n",
    "        kp1, des1 = self.orb.detectAndCompute(last_image, None)\n",
    "        kp2, des2 = self.orb.detectAndCompute(image, None)\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "        # Filter matches using Lowe's ratio test\n",
    "        good_matches = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "        \n",
    "        return kp1, kp2, good_matches\n",
    "\n",
    "\n",
    "    def handle_valid_matches(self, kp1, kp2, last_image, image, valid_matches):\n",
    "        \"\"\"Handle valid matches by checking for sufficient inliers and updating the image list.\"\"\"\n",
    "        img1_pts, img2_pts = zip(*[(kp1[match.queryIdx].pt, kp2[match.trainIdx].pt) for match in valid_matches])\n",
    "        img1_pts = np.float32(img1_pts).reshape(-1, 1, 2)\n",
    "        img2_pts = np.float32(img2_pts).reshape(-1, 1, 2)\n",
    "        _, mask = cv2.findHomography(img1_pts, img2_pts, cv2.RANSAC, 5.0)\n",
    "        if 35 < np.count_nonzero(mask) < 1500:\n",
    "            self.images.append(self.preprocess_image(image))\n",
    "            self.update_loading(self.frame_count, self.total_images)\n",
    "\n",
    "\n",
    "    def finalize_progress_bar(self):\n",
    "        \"\"\"Finalize the progress bar after processing all frames.\"\"\"\n",
    "        self.update_loading(self.total_images, self.total_images)\n",
    "        self.capture.release()\n",
    "\n",
    "    # Open the video\n",
    "    def open_video(self):\n",
    "        # Open a file dialog to choose the video file\n",
    "        self.video_path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4;*.avi\"), (\"All files\", \"*.*\")])\n",
    "        self.video_name = self.video_path[self.video_path.rfind('/')+1:self.video_path.rfind('.')]\n",
    "        self.preprocess_video()\n",
    "\n",
    "    def show_image(self, name, image):\n",
    "        cv2.namedWindow(name, 0)\n",
    "        cv2.resizeWindow(name, 800, 600)\n",
    "        cv2.imshow(name, image) \n",
    "\n",
    "\n",
    "    def find_boundrect(self, image):\n",
    "        '''find the boundrect for image'''\n",
    "        binary_image = cv2.Canny(image, 50, 150) # Canny\n",
    "\n",
    "        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "        # If no boundrect is found, print the prompt and return a default rectangle\n",
    "        if not contours:\n",
    "            return (0, 0, image.shape[1], image.shape[0])\n",
    "\n",
    "        # Look for the outline with the largest area\n",
    "        corners = max(contours, key=cv2.contourArea)\n",
    "        (x, y, w, h) = cv2.boundingRect(corners)\n",
    "        return (x, y, w, h)\n",
    "\n",
    "    def generate_panorama(self):\n",
    "        self.open_video()\n",
    "        if not self.images:\n",
    "            messagebox.showerror(\"Error\", \"No video loaded.\")\n",
    "            return\n",
    "\n",
    "        stitched_image = self.stitch_images()\n",
    "        if stitched_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Generate panorama failed. Please upload a clear video.\")\n",
    "            return\n",
    "        \n",
    "        self.save_and_display_results(stitched_image)\n",
    "\n",
    "    def stitch_images(self):\n",
    "        \"\"\"Stitch images using OpenCV's Stitcher.\"\"\"\n",
    "        images = np.array(self.images)\n",
    "        stitcher = cv2.Stitcher_create()\n",
    "        status, stitched_image = stitcher.stitch(images)\n",
    "        if status == cv2.Stitcher_OK:\n",
    "            return stitched_image\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "    def save_and_display_results(self, stitched_image):\n",
    "        \"\"\"Save and display the panorama and cropped panorama images.\"\"\"\n",
    "        panorama_image_name = f'Panorama_{self.video_name}.jpg'\n",
    "        crop_panorama_image_name = f'Cropped_Panorama_{self.video_name}.jpg'\n",
    "        \n",
    "        cv2.imwrite(panorama_image_name, stitched_image)\n",
    "        cropped_image = self.crop_image(stitched_image)\n",
    "        cv2.imwrite(crop_panorama_image_name, cropped_image)\n",
    "        \n",
    "        self.show_image(\"Panorama\", stitched_image)\n",
    "        self.show_image(\"Cropped Panorama\", cropped_image)\n",
    "        cv2.waitKey()\n",
    "\n",
    "    def crop_image(self, stitched_image):\n",
    "        \"\"\"Crop the panorama image to remove black borders.\"\"\"\n",
    "        stitched_image = cv2.copyMakeBorder(stitched_image, 2, 2, 2, 2, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        gray = cv2.cvtColor(stitched_image, cv2.COLOR_BGR2GRAY)\n",
    "        binary_image = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # Initialize a mask to find the bounding rectangle\n",
    "        mask = np.zeros(binary_image.shape, dtype=\"uint8\")\n",
    "        x, y, w, h = self.find_boundrect(binary_image)\n",
    "        cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)\n",
    "\n",
    "        min_rect = mask.copy()\n",
    "        sub_rect = mask.copy()\n",
    "        # Iteratively erode the mask until there are no non-zero pixels left in the subtracted region\n",
    "        while cv2.countNonZero(sub_rect) > 0:\n",
    "            min_rect = cv2.erode(min_rect, None)\n",
    "            sub_rect = cv2.subtract(min_rect, binary_image)\n",
    "\n",
    "        x, y, w, h = self.find_boundrect(min_rect)\n",
    "        return stitched_image[y:y + h, x:x + w]\n",
    "\n",
    "    def show_about(self):\n",
    "        messagebox.showinfo(\"About\", \"Panorama Builder Version 1.0\")\n",
    "        \n",
    "    # Ask whether the user want to exit the programme\n",
    "    def quit(self):\n",
    "        message = messagebox.askokcancel(\"Info\", \"Do you want to quit?\", default = messagebox.CANCEL)\n",
    "        if message:\n",
    "            self.tk_window.destroy()\n",
    "\n",
    "# Create the Tkinter gui\n",
    "tk_window = tk.Tk()\n",
    "app = PanoramaBuilder(tk_window)\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "tk_window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f68a15-fdac-4835-8044-8b5d1a4d2d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
